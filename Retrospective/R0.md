# RETROSPECTIVE (Team 02)

The retrospective should include _at least_ the following
sections:

- [process measures](#process-measures)
- [quality measures](#quality-measures)
- [general assessment](#assessment)

## PROCESS MEASURES

### Macro statistics

- Number of stories committed vs. done
  - Commited: 4
  - Done: 3
- Total points committed vs. done
  - Commited: 11
  - Done: 10
- Nr of hours planned vs. spent (as a team)
  - Planned: 48h
  - Spent: 46h 15m

**Remember** a story is done ONLY if it fits the Definition of Done:

- Unit Tests passing
- Code review completed
- Code present on VCS
- End-to-End tests performed

> Please refine your DoD if required (you cannot remove items!)

### Detailed statistics

| Story                | # Tasks                                    | Points | Hours est. | Hours actual |
| -------------------- | ------------------------------------------ | ------ | ---------- | ------------ |
| _#0 Setup tasks_     |                                            |        | 8          | 6 35m        |
|                      | Setup frontend                             |        | 1          | 1            |
|                      | Setup backend                              |        | 2          | 1            |
|                      | Landing page                               |        | 1          | 1 35m        |
|                      | Interaction client-server                  |        | 4          | 3            |
| _#1 Config counters_ |                                            | 5      | ????       | 16 50m       |
|                      | Admin interface                            |        | 3          | 4 10m        |
|                      | Queue setup                                |        | 1          | 1            |
|                      | Add/remove services endpoints              |        | 2          | 7 30m        |
|                      | Connection client-server for admin actions |        | 30m        | 30m          |
|                      | Unit testing                               |        | ????       | 3 40m        |
| _#2 New client_      |                                            | 3      | ?          | 5 45m        |
|                      | Officer interface                          |        | 1          | 1            |
|                      | Officer logic                              |        | ????       | 3 30m        |
|                      | Update queue                               |        | 2          | 1 15m        |
| _#3 Get a ticket_    |                                            | 2      | 7 30m      | 8 50m        |
|                      | Client interface                           |        | 5          | 6            |
|                      | Get services                               |        | 1          | 1            |
|                      | Add client                                 |        | 1 30m      | 1 50m        |

> place technical tasks corresponding to story `#0` and leave out story points (not applicable in this case)

- Hours per task average, standard deviation (estimate and actual): ????
- Total task estimation error ratio: sum of total hours estimation / sum of total hours spent - 1: ????

## QUALITY MEASURES

- Unit Testing:
  - Total hours estimated: We estimated tickets globally (not per type of tasks)
  - Total hours spent: 1h 25m
  - Nr of automated unit test cases: 29
  - Coverage (if available):

| File           | % Stmts | % Branch | % Funcs | % Lines | Uncovered Line #s |
| -------------- | ------- | -------- | ------- | ------- | ----------------- |
| All files      | 96.11   | 92.1     | 95.65   | 96.07   |
| dataService.js | 100     | 100      | 100     | 100     |
| routes.js      | 95.5    | 92.1     | 95.45   | 95.45   | 30,113,161,191    |
| server.js      | 100     | 100      | 100     | 100     |

- E2E testing:
  - Total hours estimated : We estimated tickets globally (not per type of tasks)
  - Total hours spent : 6h 25m
- Code review
  - Total hours estimated : We estimated tickets globally (not per type of tasks)
  - Total hours spent : 1h 45m

## ASSESSMENT

- What caused your errors in estimation (if any)?

  - [LUCA] Our poor experience in code development, the lack of a clear idea of the project.
  - [LORENZO] Personally, I spent a lot more time than I thought in writing the tests, and in learning how to do that. When I did the estimation for my task, I considered only the main code development.
  - [LENNY] The tests. Its hard to expect how much time you will spend on them. Sometimes everything goes right so you are not losing lots of time but sometimes you have to debug a lot and it takes a lot of time.
  - [CARLOS] The main issue was not having a clear idea of what the project would have looked like so that probably lead us to have superficial estimations and also we didn't put into consideration other possible issues that we eventually encountered during development such as bugs or integration problems.

- What lessons did you learn (both positive and negative) in this sprint?

  - [LUCA] The front-end take more time than the back-end.
  - [LUCA] We need to communicate more between team members. Perhaps we can divide ourselves into subgroups linked to the aspect we develop.
  - [LORENZO] We have to divide well the tasks because some people risk to work less than others.
  - [LENNY] Tests are time consumming.
  - [LENNY] I like backend as much as frontend.
  - [LORENZO] What is a mok, the difference between unit tests and integration tests (not sure about this)
  - [CARLOS] We learned that we need to write tasks better and improve them during the spring if needed. We also need to have a better communication about the conventions that we adopt when writing code and have more balanced inner teams between front-end and back-end development. In addition we need to sketch in advance how the app is going to look and define all the endpoints and data structures properly. The positive takes are that we were able to use GitHub to manage our workflows and everyone in the team took on some tasks and completed those.

- Which improvement goals set in the previous retrospective were you able to achieve? (N.A)

- Which ones you were not able to achieve? Why? (N.A)

- Improvement goals for the next sprint and how to achieve them (technical tasks, team coordination, etc.)

  > Propose one or two

  - [LUCA] The general idea is to be more organized than last sprint, and therefore make it less chaotic.
  - [LUCA] Some team members (not me ahah) have worked harder then others due to errors in estimation, we must try to divide the work more equally among us.
  - [LORENZO] We have to dedicate much more time in DEFINING WELL what we are going to do BEFORE actually start doing it.
  - [LORENZO] The APIs must be defined well, using standard specifications.
  - [LENNY] Describe well stories and tasks to make sure everyone understand the goal of the task so that there is no multiple people working on the same task.
  - [LENNY] Stricly follow the tickets and try to make a PR for each ticket. (no PR with only tests because we forgot them...)
  - [LORENZO] The database also must be defined before everything else, at least by more than a single person because it is a crucial activity.
  - [LORENZO] We should write a list of what we have done everytime we do something, so that we see in any moment what the others are doing.
    - [Lenny] Youtrack ?
  - [CARLOS] Write tasks in a better way and improve them during the spring if needed.
  - [CARLOS] Define conventions to adopt when writing code and sketch in advance how the app is going to look to define all the endpoints and data structures properly.

- One thing you are proud of as a Team!!

  - [LUCA] despite our little experience, we have knowledge in many different fields and the final project we delivered was very good.
  - [LORENZO] the final result was really good.
  - [LENNY] The team work was great. We we able to work together and help each other when needed.
